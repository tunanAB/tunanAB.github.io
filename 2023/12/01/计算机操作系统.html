<h3 id="第一章-概论">第一章 概论</h3>

<ul>
  <li>
    <p>操作系统：计算机操作系统是指控制和管理计算机的软、硬件资源，合理组织计算机的工作流程， 方便用户使用的程序集合。</p>
  </li>
  <li>
    <p>目标：方便性、有效性、可扩充性、开放性。</p>
  </li>
  <li>
    <p>发展历程（大概了解）：</p>

    <ul>
      <li>
        <p>人工操作：用户独占全机、CPU等待人工操作。</p>
      </li>
      <li>
        <p>单道批处理系统：内存中始终只保持一道作业，系统资源得不到充分的利用。</p>
      </li>
      <li>
        <p>多道批处理系统：用户提交的作业存放在外存上排成一个队列，由作业调度程序按一定的算法，从后备队列中选择若干个作业调入内存，使它们共享CPU和系统中的各种资源。</p>

        <ul>
          <li>
            <p>优点：资源利用率高、系统吞吐量大。</p>
          </li>
          <li>
            <p>缺点：平均周转时间长、无交互能力。</p>
          </li>
        </ul>
      </li>
      <li>分时系统：多个用户分享使用同一台计算机，多个程序分时共享硬件和软件资源，通常按时间 片来分配各个程序在CPU上执行的轮换时间。
        <ul>
          <li>特征：</li>
          <li>多路性：系统允许将多台终端同时连接到一台主机上，并按分时原则为每个用户服 务。</li>
          <li>独立性：每个用户在各自的终端上进行操作，彼此之间互不影响。</li>
          <li>及时性：用户的请求能在很短时间内获得响应。</li>
          <li>交互性：用户可通过终端与系统进行广泛的人机对话。</li>
        </ul>
      </li>
      <li>实时系统：系统能及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所 有实时任务协调一致地运行。</li>
    </ul>
  </li>
  <li>
    <p>功能：</p>

    <ul>
      <li>作为用户与计算机硬件系统之间的接口：用户在OS帮助下能够方便、快捷、可靠地操纵计算机硬件和运行自己的程序。</li>
      <li>作为计算机系统资源的管理者：OS可以对计算机四类资源：处理机、存储器、I/O设备以及文 件进行有效管理。</li>
      <li>实现了对计算机资源的抽象：不仅增强了系统的功能，还隐藏了对硬件操作的具体细节，实现 了对计算机硬件操作的多个层次的抽象模型。</li>
    </ul>
  </li>
  <li>
    <p>特征（并发和共享是最基本的特征）：</p>

    <ul>
      <li>并发性：在操作系统中同时存在许多活动，多个事件会在同一时间段内发生。
        <ul>
          <li>并行：两个或多个事件在同一时刻发生 （区别）</li>
        </ul>
      </li>
      <li>共享性：系统中的资源可供内存中多个并发执行的进程共同使用。
        <ul>
          <li>互斥共享：一段时间只允许一个进程访问（临界资源）</li>
          <li>同时访问：一段时间内允许多个进程同时访问。</li>
        </ul>
      </li>
      <li>虚拟性：通过某种技术把一个物理实体变为若干个逻辑上的对应物。
        <ul>
          <li>举例：虚拟处理机、虚拟存储器、虚拟设备技术。</li>
        </ul>
      </li>
      <li>异步性：指进程的执行顺序和执行时间的不确定性。</li>
    </ul>
  </li>
  <li>
    <p>分类：批处理操作系统、分时系统、实时操作系统、网络操作系统、分布式操作系统、多处理机操 作系统、嵌入式操作系统</p>
  </li>
</ul>

<h3 id="第二章-进程">第二章 进程</h3>

<h4 id="1-概念">1. 概念</h4>

<p>进程：是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。</p>

<ul>
  <li>进程特征：
    <ul>
      <li>动态性：进程是程序的一次执行，具有一定的生命期，是动态地产生、变化和消亡的。</li>
      <li>并发性：进程之间的动作在时间上可以重叠。</li>
      <li>独立性：进程是系统调度和资源分配的独立单位，它具有相对独立的功能，拥有自己独立的进程控制块PCB。</li>
      <li>异步性：各个并发进程按照各自独立的、不可预知的速度向前推进。</li>
      <li>交互性：并发进程之间具有直接或间接的关系，在运行过程中需要进行必要的交互，以完成特定的任务。</li>
    </ul>
  </li>
  <li>程序与进程的区别（简答题）：
    <ul>
      <li>程序是静态的，进程是动态的</li>
      <li>进程与程序的组成不同，进程＝程序＋数据＋PCB</li>
      <li>进程的存在是暂时的，程序的存在是永久的</li>
      <li>一个程序可以对应多个进程，一个进程可以包含多个程序</li>
    </ul>
  </li>
</ul>

<h4 id="2进程的表示和状态转换">2.进程的表示和状态转换</h4>

<ul>
  <li>进程控制块PCB：系统为了管理进程设置的一个专门的数据结构，用来记录进程的外部特征，描述 进程的变化过程。</li>
  <li>PCB是系统感知进程存在的唯一标志，进程与PCB是一一对应的。</li>
  <li>PCB主要包含以下信息：
    <ul>
      <li>进程标识符：用于唯一表示一个进程，包含外部标识符和内部标识符。</li>
      <li>处理机状态：由处理机的各种寄存器中的内容组成，包括通用寄存器R、指令寄存器PC、程序 状态字PSW、用户栈指针SP等。</li>
      <li>进程调度信息：有关进程的状态及有关进程调度的信息，包括：进程状态、进程优先级、进程调度所需的其它信息。</li>
      <li>进程控制信息：用于进程控制所必须的信息，包括：程序和数据的地址、进程同步和通信机制、资源清单、链接指针。</li>
    </ul>
  </li>
  <li>
    <p>PCB组织方式（了解）：</p>

    <ul>
      <li>
        <p>线性方式：将所有PCB组织在一张线性表中。</p>
      </li>
      <li>
        <p>链接方式：通过PCB中的链接字链接成一个队列。</p>
      </li>
      <li>
        <p>索引方式：根据所有进程状态的不同建立几张索引表。</p>
      </li>
    </ul>
  </li>
  <li>最基本的进程状态有三种：
    <ul>
      <li>运行状态：进程占有CPU，并在CPU上运行</li>
      <li>就绪状态： 一个进程已经具备运行条件，但由于无CPU暂时不能运行的状态（当调度给其 CPU时，立即可以运行）</li>
      <li>阻塞（等待）状态：指进程因等待某种事件的发生而暂时不能运行的状态（即使CPU空闲，该 进程也不可运行）</li>
    </ul>
  </li>
  <li>增加的状态：
    <ul>
      <li>创建状态：进程刚创建，但还不能运行</li>
      <li>结束状态：进程已结束运行，回收除PCB之外的其他资源，并让其他进程从PCB中收集有关信 息</li>
      <li>挂起状态：一些低优先级进程可能等待较长时间而被对换至外存，为运行进程提供足够内存
        <ul>
          <li>阻塞挂起（静止阻塞）：进程在外存并等待某事件的出现。</li>
          <li>就绪挂起（静止就绪）：进程在外存，但只要进入内存即可运行。
            <ul>
              <li>终端用户的需要</li>
              <li>父进程的请求</li>
              <li>负荷调节的需要</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="../images/image-20230628155936094.png" alt="image-20230628155936094" /></p>

<ul>
  <li>创建-&gt;活动就绪：在系统的性能和内存容量允许的情况下，进程的状态会转换成就绪状态。</li>
  <li>创建-&gt;静止就绪：若系统当前资源状况和性能要求不允许的情况下，相应程序状态将转化为静止就 绪被安置在外存，不参与调度</li>
</ul>

<h4 id="3进程控制">3.进程控制</h4>

<p>OS内核：将一些与硬件紧密相关的模块、各种常用设备的驱动程序以及运行频率较高的模块都安排在紧靠硬件的软件层次中，将它们常驻内存。</p>

<ul>
  <li>处理即的执行状态
    <ul>
      <li>系统态：又称为管态，也称为内核态。它具有较高的特权，能执行一切指令，访问所有的寄存器和存储区。</li>
      <li>用户态：又称为目态。它是具有较低特权的执行状态，仅能执行规定的指令，访问指定的寄存器和存储区。这样可以防止应用程序对OS的破坏</li>
    </ul>
  </li>
  <li>OS内核一般都包含两大功能：
    <ul>
      <li>支撑功能：
        <ul>
          <li>中断处理</li>
          <li>时钟管理：如时间片轮转调度</li>
          <li>原语操作：原语就是由若干条指令组成，用于完成一定功能的一个过程。 （原子操作）</li>
        </ul>
      </li>
      <li>资源管理功能：
        <ul>
          <li>进程管理</li>
          <li>存储器管理</li>
          <li>设备管理</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="1进程创建">（1）进程创建</h5>

<ul>
  <li>创建事件：
    <ul>
      <li>用户登录</li>
      <li>作业调度</li>
      <li>提供服务</li>
      <li>应用请求</li>
    </ul>
  </li>
  <li>创建步骤：
    <ul>
      <li>申请空白PCB，为新进程申请获得唯一的数字标识符</li>
      <li>为新进程分配其运行所需的资源</li>
      <li>初始化进程控制块PCB：初始化标识信息、初始化处理机状态信息、初始化处理机控制信息</li>
      <li>如果进程就绪队列能够接纳新进程，则将其插入就绪队列</li>
    </ul>
  </li>
</ul>

<h4 id="4进程同步互斥">4.进程同步/互斥</h4>

<p>进程同步机制：对多个相关进程在执行次序上进行协调，使并发执行的进程之间能按照一定的规则共享 系统资源，并能很好地相互合作，从而使程序的执行具有可再现性。</p>

<ul>
  <li>两种形式的制约关系：
    <ul>
      <li>直接制约关系：相互协作，等待来自其他进程的信息，“同步”</li>
      <li>间接制约关系：进行竞争，独占分配到的部分或全部共享资源，“互斥“</li>
    </ul>
  </li>
  <li>进程同步：相互协调的几个进程在某些确定点上协调它们的工作，一个进程到达了这些点后，除非 另一进程已完成了某些操作，否则就需要停下来等待这些操作的完成。</li>
  <li>进程互斥：两个或两个以上的进程由于不能同时使用同一资源，只能一个进程使用完了另一个进程才能使用的现象。</li>
  <li>临界资源：一次仅允许一个进程访问的资源。</li>
  <li>
    <p>临界区：临界段，在每个程序中，访问临界资源的那段程序。</p>
  </li>
  <li>
    <p>进入区：在进入临界区之前，检查可否进入临界区的一段代码。如果可以进入临界区，通常设置相 应”正在访问临界区”标志</p>
  </li>
  <li>
    <p>退出区：用于将”正在访问临界区”标志清除 。</p>
  </li>
  <li>
    <p>剩余区：代码中的其余部分。</p>
  </li>
  <li>同步机制应遵循的准则：
    <ul>
      <li>空闲让进</li>
      <li>忙则等待</li>
      <li>有限等待：应保证在有限时间内能进入临界区，以免陷入”死等“状态。</li>
      <li>让权等待：当进程不能进入临界区时，立即释放处理机以免陷入”忙等“状态。</li>
    </ul>
  </li>
  <li>进程同步和互斥间的关系：
    <ul>
      <li>相似处：互斥是同步的一种特殊情况</li>
      <li>差别处：互斥是竞争共享资源，这种竞争没有固定的必然联系，谁竞争到谁就使用而同步则涉及资源，进程之间的关系</li>
    </ul>
  </li>
</ul>

<h5 id="1硬件同步机制">（1）硬件同步机制</h5>

<ol>
  <li>关中断：进程在临界区执行期间，计算机系统不响应中断。</li>
  <li>Test-and-Set指令:为每个临界资源设置一个全局布尔变量lock，并赋初值false，表示资源空闲。在 进入区利用TS进行检查：有进程在临界区时，重复检查；直到其它进程退出时，检查通过；</li>
</ol>

<p>当进程进入后会将lock值设为TRUE表示资源正在被使用，使用完后会将其设为false。</p>

<ol>
  <li>Swap指令：为每个临界资源设置一个全局布尔变量lock，其初值为false，在每个进程中再利用一 个局部变量key，初值为true，重复交换key与lock的值，直到key的值为false后代表可以占用临界 资源。</li>
</ol>

<ul>
  <li>缺点：
    <ul>
      <li>等待要耗费CPU时间，，不能实现”让权等待“。</li>
      <li>可能导致”饥饿“，有的进程可能一直无法进入临界区。</li>
      <li>可能死锁。</li>
    </ul>
  </li>
</ul>

<h5 id="2dijkstra算法">（2）Dijkstra算法</h5>

<ul>
  <li>信号量S的物理意义：
    <ul>
      <li>S&gt;0表示有S个资源可用</li>
      <li>S=0表示无资源可用</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>S&lt;0则</td>
              <td>S</td>
              <td>表示S等待队列中的进程个数</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>P原语P(S)：表示申请一个资源</li>
  <li>V原语V(S)：表示释放一个资源</li>
</ul>

<p>利用mutex信号量实现互斥：</p>

<p>对P、V操作的讨论（重要！！）：</p>

<h4 id="5进程通信掌握pv操作实现的通信">5.进程通信（掌握PV操作实现的通信）</h4>

<p>进程通信：指进程之间可直接以较高的效率传递较多数据的信息交换方式。</p>

<p>**分类： **</p>

<p><strong>（1）共享存储器系统</strong></p>

<ul>
  <li>基于共享数据结构的通信方式：诸进程公用某些数据结构，进程通过它们交换信息。</li>
  <li>基于共享存储区的通信方式：在存储器中划出一块共享存储区,申请者把获得的共享存储分区连接到 本进程上，此后可读写该分区</li>
</ul>

<p><strong>（2）消息传递系统</strong>：进程间的数据交换以消息为单位，程序员利用系统的通信原语实现通信  分为<strong>直接通信</strong>与<strong>间接通信</strong>。</p>

<p><strong>（3）管道通信</strong></p>

<p>管道：指用于连接一个读进程和一个写进程的文件</p>

<ul>
  <li>互斥访问</li>
  <li>写后读，读后写的同步</li>
  <li>只有在管道双方都存在时才能通信</li>
</ul>

<p><strong>管道破裂</strong></p>

<p>如果一个管道的读端已经关闭，进程还继续向写端写数据， 则进程会收到一个SIGPIPE信号，表示管道破裂。默认动作为结束进程。读一个写端已经关闭的管道则read返回0。</p>

<p>向管道提供输入的进程（称写进程），以字符流的形式将大量数据送入管道，而接受管道输出的进程 （读进程）可从管道中接收数据。</p>

<ul>
  <li>消息传递通信的实现方式：
    <ul>
      <li>直接通信方式：消息缓冲
        <ul>
          <li>采用进程的消息缓冲队列</li>
          <li>消息发送者将消息直接放在接收者的消息缓冲队列</li>
        </ul>
      </li>
      <li>间接通信方式：信箱通信
        <ul>
          <li>利用中间者——信箱、邮局来传递信件。</li>
          <li>发送进程将消息发送到信箱中，接收进程从信箱中取出消息</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="6线程概念">6.线程概念</h4>

<ul>
  <li>线程：
    <ul>
      <li>线程是进程内一个相对独立的、可调度的执行单元。</li>
      <li>进程中的一个运行实体，是一个CPU调度单位</li>
      <li>资源的拥有者还是进程</li>
    </ul>
  </li>
  <li>进程与线程对比：
    <ul>
      <li>调度：线程上下文切换比进程上下文切换要快，同进程内的线程切换时间比进程短</li>
      <li>并发性：一个进程中的所有线程都能并发执行，不同进程中的线程也能并发执行。</li>
      <li>拥有资源：进程间相互独立，同一进程的各线程间资源共享。</li>
      <li>独立性：同一进程中的不同线程之间的独立性要比不同进程之间的独立性低得多。</li>
      <li>系统开销：在创建或撤销进程时，系统为之分配的资源明显大于线程创建或撤销时的开销。</li>
      <li>支持多处理机系统：多线程进程可以将一个进程中的多个线程分配到多个处理机上，使它们并行执行。</li>
    </ul>
  </li>
</ul>

<p>线程也有三个基本状态：执行、就绪、阻塞。</p>

<p>线程控制块TCB：通常含有线程标识符、寄存器、线程运行状态、优先级、线程专有存储区、信号屏蔽、堆栈指针。</p>

<h4 id="7线程实现">7.线程实现</h4>

<p><strong>（1）内核支持线程KST（Kernel Supported Threads）</strong>：在内核空间为每一个内核线程设置了一个线程控制块，内核根据该控制块而感知某线程的存在，并对其加以控制。</p>

<ul>
  <li>优点：
    <ul>
      <li>在多处理系统中，内核能够同时调度通过一进程中的多个线程并行执行。</li>
      <li>如果进程中一个线程被阻塞，内核可以调度进程其它线程占有处理器，也可以运行其它进程中的线程。</li>
      <li>线程的切换比较快，切换开销小</li>
      <li>采用多线程技术，可以提高系统的执行速度和效率。</li>
    </ul>
  </li>
  <li>缺点：
    <ul>
      <li>对于用户的线程切换时，其模式切换开销较大。</li>
    </ul>
  </li>
</ul>

<p><strong>（2）用户级线程ULT（User Level Threads）</strong>：在用户空间中实现的，对线程的创建、撤销、同步与通信等功能，都无需内核的支持。</p>

<ul>
  <li>优点：
    <ul>
      <li>线程切换不需要转换到内核空间。</li>
      <li>调度算法可以是进程专用的。</li>
      <li>用户级进程的实现与OS平台无关，所有应用程序都可以对之进行共享。</li>
    </ul>
  </li>
  <li>缺点：
    <ul>
      <li>系统调用阻塞问题。当线程执行一个系统调用时，进程内所有线程都会被阻塞。</li>
      <li>在单纯的用户级线程实现方式中，进程中仅有一个线程能执行，在该线程放弃CPU之前，其它 线程只能等待。</li>
    </ul>
  </li>
</ul>

<p>（3）组合方式</p>

<p>用户级线程和内核支持线程两种方式结合。</p>

<h3 id="第三章-处理机调度与死锁">第三章 处理机调度与死锁</h3>

<h4 id="1调度层次与目标">1.调度层次与目标</h4>

<ul>
  <li>层次：
    <ul>
      <li>高级调度：也称为作业调度或宏观调度，从用户工作流程的角度，一次提交的若干个流程，其中每个程序按照进程调度。时间上通常是分钟、小时或天。</li>
      <li>中级调度：涉及进程在内外存间的交换，从存储器资源管理的角度来看，把进程的部分或全部换出到外存上，将当前进程所需部分换入到内存。</li>
      <li>低级调度：也称<strong>进程调度</strong>、<strong>微观调度</strong>，从处理机资源分配的角度来看，处理机需要经常选择就绪进程或线程进入运行状态。</li>
    </ul>
  </li>
  <li>目标：
    <ul>
      <li>处理机调度算法共同目标：
        <ul>
          <li>资源利用率：</li>
          <li>公平性：使进程都获得合理的CPU时间</li>
          <li>平衡性：尽可能保持系统资源的平衡性</li>
          <li>策略强制执行：对所指定的策略如安全策略必须准确执行</li>
        </ul>
      </li>
      <li>批处理系统目标：
        <ul>
          <li>平均周转时间短：作业提交给系统到作业完成为止的时间段。
            <ul>
              <li>作业在外存后备队列上等待调度的时间</li>
              <li>进程在就绪队列上等待进程调度的时间</li>
              <li>进程在CPU上执行的时间</li>
              <li>进程等待I/O操作完成的时间</li>
            </ul>
          </li>
          <li>系统吞吐量高：单位时间内系统所完成的作业数</li>
          <li>处理机利用率高</li>
        </ul>
      </li>
      <li>分时系统目标：
        <ul>
          <li>响应时间快</li>
          <li>均衡性：指系统响应时间的快慢与用户所请求服务的复杂性相适应。</li>
        </ul>
      </li>
      <li>实时系统目标：
        <ul>
          <li>截止时间的保障：指某任务开始执行的最迟时间。</li>
          <li>可预测性</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="2作业与作业调度">2.作业与作业调度</h4>

<ul>
  <li>作业：比程序更广泛的概念，程序+数据+作业说明书</li>
  <li>作业控制块JCB：是作业在系统中存在的标志</li>
  <li>周转时间：作业提交给系统到作业完成为止的时间段。</li>
  <li>带权周转时间：周转时间/进程服务时间</li>
  <li>进程调度方法：
    <ul>
      <li>非剥夺调度：某一进程被调度运行后，除非由于它自身的原因不能运行，否则一直运行下去。</li>
      <li>剥夺调度：当有比正在运行的进程优先级更高的进程就绪时，系统可强行剥夺正在运行进程的 CPU，提供给具有更高优先级的进程使用。</li>
    </ul>
  </li>
</ul>

<p><strong>先来先服务（FCFS）</strong></p>

<ul>
  <li>每次调度是从就绪进程队列中选择一个最先进入该队列的进程分配处理机。</li>
  <li>当前作业或进程占用CPU，直到执行完或阻塞，才出让CPU（非抢占方式）；在作业或进程唤醒后 （如I/O完成），并不立即恢复执行，通常等到当前作业或进程出让CPU。</li>
  <li>最简单的算法，有利于长作业而不利于短作业。</li>
</ul>

<p><strong>最短作业优先（SJF）</strong> （short job first）</p>

<ul>
  <li>作业越短，优先级越高。</li>
  <li>缺点：
    <ul>
      <li>必须预知作业的运行时间</li>
      <li>对长作业非常不利</li>
      <li>未能依据作业的紧迫程度来划分执行的优先级</li>
    </ul>
  </li>
</ul>

<p>非抢占式：</p>

<p>抢占式：</p>

<p><strong>最短剩余时间优先（SRT）</strong></p>

<p>允许比当前进程剩余时间更短的进程来抢占</p>

<p><strong>最高响应比优先（HRRN）</strong>（highest Response Ratio Next, HRRN)</p>

<p><img src="../images/image-20230628201126125.png" alt="image-20230628201126125" /></p>

<p>这种是动态优先级算法，既让短作业优先级比较高，又考虑了长作业的等待时间</p>

<ul>
  <li>两道批处理即可以两个作业同时调度，但一次仍只能运行一个作业。</li>
</ul>

<h4 id="进程调度">进程调度</h4>

<p><strong>时间片轮转算法（RR）</strong></p>

<ul>
  <li>系统中所有就绪进程按照FCFS原则排成队列。</li>
  <li>每次调度时将CPU分派给队首进程，让其执行一个时间片。</li>
  <li>在一个时间片结束时，发生时钟中断。调度程序暂停当前进程的执行，将其送到就绪队列的末尾， 并通过上下文切换执行当前的队首进程。</li>
  <li>进程可以未使用完一个时间片，就出让CPU（如阻塞、完成）。</li>
  <li>响应时间的要求：T(响应时间)=N(进程数目)*q(时间片)</li>
</ul>

<p><strong>基于优先级的调度算法</strong></p>

<ul>
  <li>系统为每个进程设置一个优先数（对应一个优先级），把所有的就绪进程按优先级从大到小排序， 调度时从就绪队列中选择优先级最高的进程投入运行，仅当占用CPU的进程运行结束或因某种原因 不能继续运行时，系统才进行重新调度 。</li>
  <li>剥夺方式：
    <ul>
      <li>非剥夺</li>
      <li>可剥夺</li>
    </ul>
  </li>
  <li>优先级类型：
    <ul>
      <li>静态优先级：创建进程时就确定，直到进程终止前都不改变。</li>
      <li>动态优先级：在创建进程时赋予的优先级，在进程运行过程中可以自动改变，以便获得更好的调度性能。如等待时间延长优先级提高、每执行一个时间片就降低优先级等。</li>
    </ul>
  </li>
</ul>

<p><strong>多级队列算法</strong></p>

<ul>
  <li>根据作业或进程的性质或类型的不同，将就绪队列再分为若干个子队列。</li>
  <li>每个作业固定归入一个队列。</li>
  <li>各队列不同处理：不同队列可有不同的优先级、时间片长度、调度策略等。如：系统进程、用户交互进程、批处理进程等。</li>
</ul>

<p><strong>多级反馈队列算法</strong></p>

<ul>
  <li>时间片轮转算法和优先级算法的综合和发展</li>
  <li>优点：
    <ul>
      <li>为提高系统吞吐量和缩短平均周转时间而照顾短进程</li>
      <li>为获得较好的I/O设备利用率和缩短响应时间而照顾I/O型进程</li>
      <li>不必估计进程的执行时间，动态调节</li>
    </ul>
  </li>
  <li>优先级分组法：组间可剥夺，组内不可剥夺（组内相同优先级则按FCFS处理）
    <ul>
      <li>基本思想：
        <ul>
          <li>设置多个就绪队列，分别赋予不同的优先级，如逐级降低，队列1的优先级最高。每个队列执 行时间片的长度也不同，规定优先级越低则时间片越长，如逐级加倍</li>
          <li>新进程进入内存后，先投入队列1的末尾，按FCFS算法调度；若按队列1一个时间片未能执行 完，则降低投入到队列2的末尾，同样按FCFS算法调度；如此下去，降低到最后的队列，则 按”时间片轮转”算法调度直到完成。</li>
          <li>仅当较高优先级的队列为空，才调度较低优先级的队列中的进程执行。如果进程执行时有新进 程进入较高优先级的队列，则抢先执行新进程，</li>
          <li>并把被抢先的进程投入原队列的末尾</li>
        </ul>
      </li>
      <li>特点：</li>
      <li>短作业优先</li>
      <li>输入/输出进程优先</li>
      <li>运算型进程有较长的时间片</li>
      <li>采用了动态优先级, 使用珍贵资源ＣＰＵ的进程优先级不断降低。 采用了可变时间片以适应不 同进程对时间的要求, 运算型进程将获得较长的时间片</li>
    </ul>
  </li>
</ul>

<h4 id="3实时调度">3.实时调度</h4>

<ul>
  <li>实时系统：
    <ul>
      <li>能够实现在指定或者确定的时间内完成系统功能和对外部或内部、同步或异步时间做出响应的系统</li>
      <li>在实时计算中，系统的正确性不仅仅依赖于计算的逻辑结果，而且依赖于结果产生的时间</li>
    </ul>
  </li>
  <li>实现实时调度基本条件：
    <ul>
      <li>提供必要的信息：就绪时间、开始截止时间和完成截止时间、处理时间、资源要求、优先级</li>
      <li>可调度的实时系统：给定m个周期性事件，事件i的周期为Pi，需要的处理时间为Ci，若处理机可调度则满足该条件：<img src="../images/image-20230628202506366.png" alt="image-20230628202506366" style="zoom: 50%;" /> ，若多处理机则将1改为N。</li>
      <li>采用抢占式调度机制：当一个优先权更高的任务到达时，允许将当前任务暂时挂起，而令高优先权任务立即投入运行，可满足该实时任务对截止时间的要求。</li>
      <li>具有快速切换机制：对外部中断的快速响应能力、快速的任务分派能力。</li>
    </ul>
  </li>
  <li>实时调度算法分类：
    <ul>
      <li>非抢占式调度算法：非抢占式轮转调度算法、非抢占式优先调度算法</li>
      <li>抢占式调度算法：基于时钟中断的抢占式优先权调度算法、立即抢占(Immediate Preemption)的优先权调度算法</li>
    </ul>
  </li>
  <li>优先级反转问题：高优先级进程因为资源被低优先级进程占据而被延迟或阻塞。</li>
  <li>解决优先级反转：优先级继承，所有使用到髙优先级进程所需资源的进程，继承髙优先级直到用完 竞争资源，再回到原来的优先级。</li>
</ul>

<p>图中进程Task3继承了Task1的优先级，使其不会被Task2抢占。</p>

<p><strong>最低松弛度优先算法（LLF)</strong> (Least Laxity First)</p>

<ul>
  <li>实现该算法时要求系统中有一个按松弛度排序的实时任务就绪队列，松弛度最低的任务排在队列最前面，调度程序总是选择就绪队列中的队首任务执行</li>
  <li>用于可抢占式调度</li>
  <li>松弛度=必须完成时间-本身运行时间-当前时间</li>
</ul>

<h5 id="4死锁">4.死锁</h5>

<ul>
  <li>可重用性资源：一次只能供一个进程安全地使用, 且不会由于使用而耗尽
    <ul>
      <li>例子: 处理器, I/O通道, 主存和辅存, 设备, 文件、数据库、信号量等数据结构</li>
    </ul>
  </li>
  <li>可消费资源：可以创建并且可以销毁的资源，数目没有限制, 当一个进程得到一个可消费资源时, 这 个资源就不再存在了
    <ul>
      <li>例子: 中断, 消息, I/O缓冲区中的信息（生产者进程创建，消费者进程消耗）</li>
    </ul>
  </li>
  <li>可抢占性资源：某进程在获得这类资源后，该资源可以再被其它进程或系统抢占（CPU、主存）</li>
  <li>不可抢占性资源：一旦系统把某资源分配给该进程后，就不能将它强行收回，只能在进程用完后自行释放（刻录机、磁带机、打印机）</li>
  <li><strong>死锁定义</strong>：如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那 么该组进程是死锁的。</li>
  <li>产生死锁原因：
    <ul>
      <li>竞争不可抢占性资源</li>
      <li>竞争可消耗资源</li>
      <li>进程推进顺序不当</li>
    </ul>
  </li>
  <li>产生死锁必要条件：
    <ul>
      <li>互斥条件：指进程对所分配到的资源进行排它性使用, 即在一段时间内某资源只能由一个进程占有。如果此时还有其它进程申请该资源,则它只能阻塞, 直至占有该资源的进程释放。</li>
      <li>请求和保持条件：进程已经保持了至少一个资源, 但又提出了新的资源要求, 而该资源又已被其它进程占有, 此时请求进程阻塞, 但又对已经获得的其它资源保持不放。</li>
      <li>不可抢占条件：进程已获得的资源, 在未使用完之前, 不能被剥夺, 只能在使用完时由自己释放。</li>
      <li>循环等待条件：在发生死锁时, 必然存在一个进程-资源的封闭的环形链. 即进程集合{P0, P1, P2, …, Pn}中的P0正在等待一个P1占用的资源; P1正在等待P2占用的资源, ……, Pn正在等待已 被P0占用的资源.</li>
    </ul>
  </li>
  <li>死锁处理方法：
    <ul>
      <li>不允许出现死锁：
        <ul>
          <li>预防死锁：设置某些限制条件来破坏产生死锁的必要条件。</li>
          <li>避免死锁：在资源动态分配过程中用某种方法防止系统进入不安全状态</li>
        </ul>
      </li>
      <li>允许出现死锁：
        <ul>
          <li>检测死锁</li>
          <li>解除死锁</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="5死锁预防">5.死锁预防</h5>

<p>概念：在系统设计时确定资源分配算法，保证不发生死锁（破坏四个必要条件的一个或几个）</p>

<p><strong>破坏请求和保持条件</strong></p>

<ul>
  <li>协议一：要求每个进程在运行前必须一次性申请它所要求的所有资源</li>
  <li>协议二：进程提出申请资源前必须释放已占有的一切资源</li>
  <li>优点：简单、易于实现</li>
  <li>缺点：
    <ul>
      <li>一个进程可能被阻塞很长时间，等待资源，发生饥饿</li>
      <li>资源严重浪费, 进程延迟运行</li>
    </ul>
  </li>
</ul>

<p><strong>破坏不可抢占条件</strong></p>

<ul>
  <li>方法一：OS可以剥夺一个进程占有的资源, 分配给其他进程（只有当两个进程优先级相同时）</li>
  <li>方法二：一个已经保持了某些资源的进程, 当它再提出新的资源请求而不能立即得到满足时, 必须释放它已经保持的所有资源, 待以后需要时再重新申请</li>
  <li>缺点：实现复杂、代价大, 反复申请/释放资源, 系统开销大, 降低系统吞吐量</li>
</ul>

<p><strong>破坏循环等待条件</strong></p>

<ul>
  <li>资源有序分配法：把系统中所有资源编号，进程在申请资源时必须严格按资源编号的递增次序进行，否则操作系统不予分配</li>
  <li>缺点：
    <ul>
      <li>此方法要求资源类型序号相对稳定, 不便于添加新类型的设备</li>
      <li>易造成资源浪费, 类型序号的安排只能考虑一般作业的情况, 限制用户简单、自主地编程</li>
      <li>限制进程对资源的请求；资源的排序占用系统开销</li>
    </ul>
  </li>
</ul>

<h5 id="6死锁避免">6.死锁避免</h5>

<p>概念：在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统可能发生死锁，则不予分配，否则予以分配</p>

<ul>
  <li>安全状态：如果存在一个由系统中所有进程构成的安全序列P1，…Pn，则系统处于安全状态</li>
  <li>不安全状态：不存在一个安全序列。不安全状态不一定导致死锁，只是很可能死锁。</li>
  <li>安全序列： 一个进程序列{P1，…，Pn}是安全的，如果对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j &lt; i )当前占有资源量之和，系统处于安全状态</li>
</ul>

<h5 id="7死锁的检测与解除">7.死锁的检测与解除</h5>

<p><strong>资源分配图：</strong></p>

<p>资源分配图化简：</p>

<ol>
  <li>找一个非孤立点进程结点且只有分配边，去掉分配边，将其变为孤立结点</li>
  <li>再把相应的资源分配给一个等待该资源的进程，即将某进程的申请边变为分配边</li>
  <li>重复以上步骤，若所有进程成为孤立结点，称该图是可完全简化的，否则称该图是不可完全简化的</li>
</ol>

<p>死锁的充分条件：当且仅当资源分配图是不可完全简化的。</p>

<ul>
  <li>死锁解除：
    <ul>
      <li>重新启动</li>
      <li>撤销进程</li>
      <li>剥夺资源</li>
      <li>进程回退</li>
    </ul>
  </li>
</ul>

<h2 id="第四章-存储管理">第四章 存储管理</h2>

<h3 id="1概念">1.概念</h3>

<p>存储管理：对有限的内存块实施有效的管理</p>

<h3 id="2存储管理方法">2.存储管理方法</h3>

<h5 id="1单一连续分配">（1）单一连续分配</h5>

<ul>
  <li>内存分为两个区域：系统区，用户区。应用程序装入到用户区，可使用用户区全部空间。最简单， 适用于单用户、单任务的OS。</li>
  <li>优点：易于管理</li>
  <li>缺点：对要求内存空间少的程序，造成内存浪费；程序全部装入，很少使用的程序部分也占用内存，只适用于单道程序</li>
</ul>

<h5 id="2固定分区">（2）固定分区</h5>

<ul>
  <li>把内存划分为若干个固定大小的连续分区。</li>
  <li>分区方法：
    <ul>
      <li>分区大小相等：处理多个类型相同的对象</li>
      <li>分区大小不等：根据程序大小，分配当前空闲、适当大小的分区。</li>
      <li>优点：易于实现，开销小</li>
      <li>缺点：内碎片造成浪费；限制了并发执行的程序数目。</li>
    </ul>
  </li>
</ul>

<h5 id="3动态分区可变式分区法">（3）动态分区/可变式分区法</h5>

<ul>
  <li>在装入程序时按其初始要求分配，或在执行过程中通过系统调用进行分配或改变分区大小。</li>
  <li>优点：没有内碎片</li>
  <li>缺点：有外碎片，如果大小不是任意的也可能出现内碎片。</li>
</ul>

<h4 id="3基于顺序搜索的动态分区分配算法">3.基于顺序搜索的动态分区分配算法</h4>

<p>（1）最先匹配法（first-fit）：按分区的先后次序，从头查找，找到符合要求的第一个分区</p>

<p>（2）下次匹配法（next-fit）：按分区的先后次序，从上次分配的分区起查找（到最后分区时再回到开 头），找到符合要求的第一个分区</p>

<p>（3）最佳匹配法（best-fit）：找到其大小与要求相差最小的空闲分区</p>

<p>（4）最坏匹配法（worst-fit）：找到最大的空闲分区</p>

<ul>
  <li>解决分区碎片：
    <ul>
      <li>多重分区：将程序装入分散存区中</li>
      <li>可再定位式分区分配/浮动分区分配：将碎片集中（紧凑或拼接）</li>
    </ul>
  </li>
</ul>

<h4 id="4覆盖与交换">4.覆盖与交换</h4>

<ul>
  <li>覆盖技术：一个作业的若干程序段，或几个作业的某些部分共享某一个存储空间。
    <ul>
      <li>缺点：
        <ul>
          <li>编程时必须划分程序模块和确定程序模块之间的覆盖关系，增加编程复杂度</li>
          <li>从外存装入覆盖文件，以时间延长来换取空间节省</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>交换技术：系统将内存中某些进程暂时移到外存，把外存中某些进程换进内存，占据前者所占用的区域。
    <ul>
      <li>原理：暂停执行内存中的进程，将整个进程的地址空间保存到外存的交换区中（换出swap out），而将外存中由阻塞变为就绪的进程的地址空间读入到内存中，并将该进程送到就绪队列（换入swap in）。</li>
      <li>优点：
        <ul>
          <li>增加并发运行的程序数目，并且给用户提供适当的响应时间</li>
          <li>编写程序时不影响程序结构</li>
        </ul>
      </li>
      <li>缺点：
        <ul>
          <li>对换入和换出的控制增加处理机开销</li>
          <li>程序整个地址空间都进行传送，没有考虑执行过程中地址访问的统计特性</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>覆盖与交换比较：
    <ul>
      <li>共同点：
        <ul>
          <li>进程的程序和数据主要放在外存，当前需要执行的部分放在内存，内外存之间进行信息交换</li>
        </ul>
      </li>
      <li>不同点：
        <ul>
          <li>交换发生在进程或作业之间，而覆盖发生在同一进程或作业内</li>
          <li>与覆盖技术相比，交换技术不要求用户给出程序段之间的逻辑覆盖结构</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="5分页存储管理">5.分页存储管理</h4>

<ul>
  <li>主存划分为大小相等的区域，称为块或内存块（物理页面，页框）</li>
  <li>作业按照主存块大小分页，从0开始编制页号，页内地址是相对于0编址</li>
  <li>连续的页存放在离散的块中，以页为单位进行分配，并按作业的页数多少来分配。逻辑上相邻的 页，物理上不一定相邻</li>
  <li>页表：一个数据结构，用来登记页号和块的对应关系和有关信息。</li>
  <li>系统为每个进程建立一个页表，页表的长度和首地址存放在该进程的进程控制块（PCB）中。</li>
  <li>页表包含：页号、块号、其它</li>
</ul>

<p>两级页表（了解）：</p>

<ul>
  <li>快表：解决页地址变换中“访问主存=访页表+访主存”的问题。</li>
  <li>把这种存放在快速存储器中的页表称为快表，把存放在内存中的页表称为慢表。</li>
  <li>快表具有并行查询能力
    <ul>
      <li>查联想表（访问一次主存）</li>
      <li>查页表（访问二次主存）</li>
    </ul>
  </li>
</ul>

<h4 id="6分段存储管理">6.分段存储管理</h4>

<ul>
  <li>用户程序划分：程序自身的逻辑关系划分为若干个程序段，每个程序段都有一个段名，且有一个段号。段号从0开始，每一段段内也从0开始编址，段内地址是连续的</li>
  <li>内存划分：内存空间被动态的划分为若干个长度不相同的区域，称为物理段，每个物理段由起始地址和长度确定</li>
  <li>内存分配：以段为单位分配内存，每一个段在内存中占据连续空间（内存随机分割，需要多少分配多少），但各段之间可以不连续存放</li>
  <li>系统需要维护的数据结构：
    <ul>
      <li>进程段表：描述组成进程地址空间的各段，可以是指向系统段表中表项的索引。每段有段基址 (base address)和段长度</li>
      <li>系统段表：系统内所有占用段</li>
      <li>空闲段表：内存中所有空闲段，可以结合到系统段表中</li>
    </ul>
  </li>
</ul>

<h5 id="段地址映射">段地址映射：</h5>

<ul>
  <li>段地址映射的数据结构有段表、段表首址指针和段表的长度。段表首址指针和段表长度存放在进程自己的PCB中。</li>
  <li>每一进程有个段表，程序的每一个段在段表中占用一个表目。</li>
  <li>段地址映射过程：
    <ul>
      <li>程序地址字送入虚地址寄存器VR中</li>
      <li>取出段号S和段内位移W</li>
      <li>根据段表首址指针找到段表，查找段号为S的表目，得到该段的首地址</li>
      <li>把段首地址与段内位移相加，形成内存地址送入MR中，并以此地址访问内存</li>
    </ul>
  </li>
</ul>

<p>快表：与分页存储管理的快表一样。</p>

<h4 id="分段与分页的区别">分段与分页的区别：</h4>

<ol>
  <li>
    <p>段是依据程序的逻辑结构划分的，页是按内存线性空间物理划分的。</p>
  </li>
  <li>
    <p>段式技术中程序地址空间是二维的，分页技术中程序地址空间是一维的。</p>
  </li>
  <li>
    <p>段是面向用户的，页对用户而言是透明的。</p>
  </li>
  <li>段长由用户决定，且各段的大小一般不相等，唯一的限制是最大长度。页长是由系统决定的，各页 的长度必须相等</li>
  <li>段的共享比页的共享更容易</li>
</ol>

<h4 id="7段页式存储管理">7.段页式存储管理</h4>

<ul>
  <li>用户程序划分：按段式划分（对用户来讲，按段的逻辑关系进行划分；对系统讲，按页划分每一 段）</li>
  <li>内存划分：按页式存储管理方案</li>
  <li>内存分配：以页为单位进行分配</li>
</ul>

<h5 id="地址映射">地址映射：</h5>

<ul>
  <li>段表：记录了每一段的页表始址和页表长度</li>
  <li>页表：记录了逻辑页号与内存块号的对应关系（每一段有一个，一个程序可能有多个页表）</li>
  <li>地址变换：先查段表，再查该段的页表</li>
</ul>

<h2 id="第五章-虚拟存储器">第五章 虚拟存储器</h2>

<h3 id="1概念-1">1.概念</h3>

<ul>
  <li>局部性原理：在一较短时间内，程序的执行仅局限于某个部分，它所访问的存储空间也局限于某个区域。</li>
  <li>虚拟存储器定义：指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。</li>
  <li>实现方式：操作系统统一管理各级存储器；内存中只存放当前要执行的程序部分，其余的保存在外存上，OS根据需要随机地将需要的部分对换到内存执行</li>
  <li>虚空间独立于实空间，指令中表示地址的位数越长，可寻址空间越大，主存+辅存不等于虚存
    <ul>
      <li>虚空间逻辑大小=可寻址范围（例如32位操作系统可寻址范围是 ）</li>
      <li>虚空间实际大小=内存+外存对换区</li>
    </ul>
  </li>
  <li>虚拟存储好处：
    <ul>
      <li><strong>大程序</strong>：可在较小的可用内存中执行较大的用户程序</li>
      <li><strong>大的用户空间</strong>：提供给用户可用的虚拟内存空间通常大于物理内存</li>
      <li><strong>并发</strong>：可在内存中容纳更多程序并发执行</li>
      <li><strong>易于开发</strong>：与覆盖技术比较，不必影响编程时的程序结构</li>
    </ul>
  </li>
  <li>虚拟存储技术的特征：
    <ul>
      <li>不连续性：物理内存分配的不连续，虚拟地址空间使用的不连续</li>
      <li>部分交换：与交换技术相比较，虚拟存储的调入和调出是对部分虚拟地址空间进行的；</li>
      <li>虚拟扩充：通过物理内存和快速外存相结合，提供大范围的虚拟地址空间（总容量不超过物理 内存和外存交换区容量之和）</li>
      <li>多次对换：程序运行期间，分别在内、外存中的程序多次对换</li>
    </ul>
  </li>
</ul>

<h4 id="2请求分页存储管理方式">2.请求分页存储管理方式</h4>

<ul>
  <li>实现方法：作业运行时，只将当前的一部分装入内存其余的放在辅存，一旦发现访问的页不在主存 中，则发出缺页中断，由o.s将其从辅存调入主存，如果内存无空块，则选择一个页淘汰。</li>
  <li>缺页率=访问失败次数/访问总次数</li>
</ul>

<h5 id="页面置换算法">页面置换算法</h5>

<ol>
  <li>先进先出页面算法（FIFO）：选择在内存中驻留时间最长的页并淘汰之</li>
  <li>最近最久未使用置换算法（LRU，Least Recently Used）：淘汰没有使用的时间最长的页</li>
  <li>最佳页面算法（OPT，Optimal）：淘汰以后不再需要的或最远的将来才会用到的页面（理论上的 算法）</li>
</ol>

<ul>
  <li>找后续访问序列中最远的一个数字（或不存在的数字）进行替换。</li>
</ul>

<ol>
  <li>最不经常使用（LFU，Least Frequently Used ）：选择访问次数最少的页面淘汰之</li>
</ol>

<h5 id="性能">性能</h5>

<ul>
  <li>影响缺页次数因素：
    <ul>
      <li>分配给进程的物理块数</li>
      <li>页本身的大小</li>
      <li>程序的编制方法</li>
      <li>页面淘汰算法</li>
    </ul>
  </li>
  <li>常驻集：指虚拟页式管理中给进程分配的物理页面数目</li>
  <li>抖动/颠簸：在虚存中，页面在内存与外存之间频繁调度，系统效率急剧下降，甚至导致系统崩 溃。这种现象称为颠簸或抖动</li>
  <li>请求分页优点：
    <ul>
      <li>提供了虚存管理方式，作业地址空间不再受实存容量的限制</li>
      <li>更有效的利用了主存，方便于多道程序运行，方便了用户</li>
    </ul>
  </li>
  <li>缺点：
    <ul>
      <li>为处理缺页中断，增加了处理机时间的开销。用时间的代价换取了空间的扩大</li>
      <li>可能因作业地址空间过大或程序数目过多等造成系统抖动；为此采取措施会增加的系统的复杂度</li>
    </ul>
  </li>
</ul>
